import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import jieba

# --- é é¢è¨­å®š ---
st.set_page_config(
    page_title="DTDA ç¬¬8å ‚ç¤¾èª²å›žé¥‹å„€è¡¨æ¿",
    page_icon="ðŸ“Š",
    layout="wide"
)

# --- ä¸­æ–‡å­—é«”è¨­å®š for Matplotlib ---
plt.rcParams['font.sans-serif'] = ['Noto Sans TC Regular']
plt.rcParams['axes.unicode_minus'] = False 

# --- è¼‰å…¥è³‡æ–™ (ä½¿ç”¨å¿«å–é¿å…é‡è¤‡è¼‰å…¥) ---
@st.cache_data
def load_data():
    df = pd.read_csv("feedback_data.csv")
    # ç°¡åŒ–æ¬„ä½åç¨±
    df.columns = [col.strip().replace('\n', '') for col in df.columns]
    short_cols = {
        'å°ˆæ¡ˆç”Ÿ/ç ”ç¿’ç”Ÿ/å¹¹éƒ¨': 'role',
        'å°æ–¼é€™æ¬¡ç¤¾èª²çš„æ»¿æ„ç¨‹åº¦ï¼ï¼ˆ1è¡¨ç¤ºéžå¸¸ä¸æ»¿æ„ï¼Œ5ç‚ºéžå¸¸æ»¿æ„ï¼‰ [èª²ç¨‹å…§å®¹æ»¿æ„åº¦]': 's_content',
        'å°æ–¼é€™æ¬¡ç¤¾èª²çš„æ»¿æ„ç¨‹åº¦ï¼ï¼ˆ1è¡¨ç¤ºéžå¸¸ä¸æ»¿æ„ï¼Œ5ç‚ºéžå¸¸æ»¿æ„ï¼‰ [è¬›å¸«çš„æŽˆèª²æŠ€å·§]': 's_lecturer',
        'å°æ–¼é€™æ¬¡ç¤¾èª²çš„æ»¿æ„ç¨‹åº¦ï¼ï¼ˆ1è¡¨ç¤ºéžå¸¸ä¸æ»¿æ„ï¼Œ5ç‚ºéžå¸¸æ»¿æ„ï¼‰ [èª²ç¨‹çµæ§‹èˆ‡å®‰æŽ’]': 's_structure',
        'å°æ–¼é€™æ¬¡ç¤¾èª²çš„æ»¿æ„ç¨‹åº¦ï¼ï¼ˆ1è¡¨ç¤ºéžå¸¸ä¸æ»¿æ„ï¼Œ5ç‚ºéžå¸¸æ»¿æ„ï¼‰ [èª²ç¨‹å¯¦ç”¨æ€§]': 's_practicality',
        'å°æ–¼é€™æ¬¡ç¤¾èª²çš„æ»¿æ„ç¨‹åº¦ï¼ï¼ˆ1è¡¨ç¤ºéžå¸¸ä¸æ»¿æ„ï¼Œ5ç‚ºéžå¸¸æ»¿æ„ï¼‰ [å­¸ç¿’åˆ°çš„æ–°çŸ¥è­˜æˆ–æŠ€èƒ½]': 's_knowledge',
        'å°æ–¼é€™æ¬¡ç¤¾èª²çš„æ»¿æ„ç¨‹åº¦ï¼ï¼ˆ1è¡¨ç¤ºéžå¸¸ä¸æ»¿æ„ï¼Œ5ç‚ºéžå¸¸æ»¿æ„ï¼‰ [äº’å‹•æ€§èˆ‡åƒèˆ‡åº¦]': 's_interaction',
        'å°æ–¼é€™æ¬¡ç¤¾èª²çš„æ»¿æ„ç¨‹åº¦ï¼ï¼ˆ1è¡¨ç¤ºéžå¸¸ä¸æ»¿æ„ï¼Œ5ç‚ºéžå¸¸æ»¿æ„ï¼‰ [èª²ç¨‹æ™‚é–“çš„åˆç†æ€§]': 's_time',
        'å°æ–¼é€™æ¬¡ç¤¾èª²çš„æ»¿æ„ç¨‹åº¦ï¼ï¼ˆ1è¡¨ç¤ºéžå¸¸ä¸æ»¿æ„ï¼Œ5ç‚ºéžå¸¸æ»¿æ„ï¼‰ [æ•´é«”æ»¿æ„åº¦]': 's_overall',
        'èª²å¾Œä¸»é¡Œç†Ÿæ‚‰åº¦ [å‡è¨­æª¢å®šåŸºç¤Žæ¦‚å¿µ]': 'f_hypothesis',
        'èª²å¾Œä¸»é¡Œç†Ÿæ‚‰åº¦ [P å€¼åŸºç¤Žæ¦‚å¿µ]': 'f_p_value',
        'èª²å¾Œä¸»é¡Œç†Ÿæ‚‰åº¦ [åž‹ä¸€/åž‹äºŒéŒ¯èª¤]': 'f_error_type',
        'èª²å¾Œä¸»é¡Œç†Ÿæ‚‰åº¦ [A/B Testing æ¨™æº–æµç¨‹]': 'f_ab_flow',
        'èª²å¾Œä¸»é¡Œç†Ÿæ‚‰åº¦ [A/B Testing Python Code]': 'f_ab_code',
        'æ ¹æ“šèª²ç¨‹æž¶æ§‹ï¼Œé€™æ¬¡è¬›åº§è®“ä½ æœ‰æ”¶ç©«çš„å…§å®¹æ˜¯ï¼Ÿï¼ˆå¯è¤‡é¸ï¼‰': 'useful_content',
        'é€™æ¬¡ç¤¾èª²æœ€å¸å¼•ä½ çš„éƒ¨åˆ†æ˜¯ä»€éº¼ï¼Ÿ': 'attractive_part',
        'å¦‚æžœæœ‰æ©Ÿæœƒå†æ¬¡åƒåŠ é¡žä¼¼èª²ç¨‹ï¼Œä½ æœƒæœŸå¾…å“ªäº›ä¸åŒä¹‹è™•ï¼Ÿæˆ–æ˜¯æœ‰ç„¡éœ€è¦èª¿æ•´çš„åœ°æ–¹ï¼Ÿ': 'suggestions',
        'æœ‰æ²’æœ‰æƒ³è¦è·Ÿè¬›å¸«å›žé¥‹æˆ–åˆ†äº«çš„å‘¢ï¼Ÿ': 'feedback_to_lecturer',
        'æœ€å¾Œé‚„æœ‰æ²’æœ‰æƒ³è¦è£œå……ä»€éº¼å‘¢ï½ž': 'additional_comments'
    }
    df.rename(columns=short_cols, inplace=True)
    return df

df = load_data()

# --- å´é‚Šæ¬„ç¯©é¸å™¨ ---
st.sidebar.title("ç¯©é¸å™¨")
st.sidebar.markdown("---")
# èº«ä»½ç¯©é¸
roles = df['role'].unique()
selected_roles = st.sidebar.multiselect(
    "é¸æ“‡èº«ä»½æŸ¥çœ‹",
    options=roles,
    default=roles
)

# æ ¹æ“šç¯©é¸çµæžœéŽæ¿¾ DataFrame
if selected_roles:
    filtered_df = df[df['role'].isin(selected_roles)]
else:
    filtered_df = df

# --- ä¸»ç•«é¢ ---
st.title("ðŸ“Š DTDA ä¸‹å­¸æœŸç¬¬8å ‚ç¤¾èª²å›žé¥‹å„€è¡¨æ¿")
st.markdown("é€™ä»½å„€è¡¨æ¿æ•´ç†äº†ã€A/B Testingã€‘ç¤¾èª²çš„å­¸å“¡å›žé¥‹ï¼Œå¯é€éŽå·¦å´ç¯©é¸å™¨æŸ¥çœ‹ä¸åŒèº«ä»½æˆå“¡çš„æ„è¦‹ã€‚")

# --- é—œéµæŒ‡æ¨™ (KPIs) ---
total_responses = len(filtered_df)
avg_satisfaction = filtered_df['s_overall'].mean()

col1, col2 = st.columns(2)
col1.metric("ç¸½å›žé¥‹æ•¸", f"{total_responses} ä»½")
col2.metric("å¹³å‡æ•´é«”æ»¿æ„åº¦", f"{avg_satisfaction:.2f} / 5.0")

st.markdown("---")

# --- å„€è¡¨æ¿å…§å®¹ (ä½¿ç”¨åˆ†é ) ---
tab1, tab2, tab3 = st.tabs(["ðŸ“ˆ æ»¿æ„åº¦èˆ‡ç†Ÿæ‚‰åº¦åˆ†æž", "â˜ï¸ æ–‡å­—å›žé¥‹èˆ‡è©žé›²", "ðŸ“„ å®Œæ•´å›žé¥‹ç•™è¨€"])

with tab1:
    st.header("å„é …æ»¿æ„åº¦èˆ‡ä¸»é¡Œç†Ÿæ‚‰åº¦åˆ†ä½ˆ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("èª²ç¨‹æ»¿æ„åº¦ (1-5åˆ†)")
        satisfaction_cols = {
            's_content': 'èª²ç¨‹å…§å®¹', 's_lecturer': 'è¬›å¸«æŠ€å·§', 's_structure': 'èª²ç¨‹çµæ§‹',
            's_practicality': 'èª²ç¨‹å¯¦ç”¨æ€§', 's_knowledge': 'æ–°çŸ¥å­¸ç¿’', 's_interaction': 'äº’å‹•åƒèˆ‡',
            's_time': 'æ™‚é–“åˆç†æ€§', 's_overall': 'æ•´é«”æ»¿æ„åº¦'
        }
        satisfaction_data = filtered_df[satisfaction_cols.keys()].mean().rename(satisfaction_cols)
        
        fig, ax = plt.subplots(figsize=(10, 8))
        satisfaction_data.sort_values().plot(kind='barh', ax=ax, color='skyblue')
        ax.set_title('å„é …æ»¿æ„åº¦å¹³å‡åˆ†æ•¸')
        ax.set_xlabel('å¹³å‡åˆ†æ•¸')
        ax.set_xlim(0, 5)
        for index, value in enumerate(satisfaction_data.sort_values()):
            ax.text(value + 0.05, index, f'{value:.2f}')
        st.pyplot(fig)

    with col2:
        st.subheader("èª²å¾Œä¸»é¡Œç†Ÿæ‚‰åº¦ (1-5åˆ†)")
        familiarity_cols = {
            'f_hypothesis': 'å‡è¨­æª¢å®š', 'f_p_value': 'På€¼æ¦‚å¿µ', 'f_error_type': 'åž‹ä¸€/äºŒéŒ¯èª¤',
            'f_ab_flow': 'A/B Testæµç¨‹', 'f_ab_code': 'A/B Testç¨‹å¼ç¢¼'
        }
        familiarity_data = filtered_df[familiarity_cols.keys()].mean().rename(familiarity_cols)

        fig, ax = plt.subplots(figsize=(10, 8))
        familiarity_data.sort_values().plot(kind='barh', ax=ax, color='lightgreen')
        ax.set_title('èª²å¾Œä¸»é¡Œç†Ÿæ‚‰åº¦å¹³å‡åˆ†æ•¸')
        ax.set_xlabel('å¹³å‡åˆ†æ•¸')
        ax.set_xlim(0, 5)
        for index, value in enumerate(familiarity_data.sort_values()):
            ax.text(value + 0.05, index, f'{value:.2f}')
        st.pyplot(fig)

with tab2:
    st.header("Word Cloud")
    
    text_cols = ['attractive_part', 'suggestions', 'feedback_to_lecturer', 'additional_comments']
    text_data = filtered_df[text_cols].fillna('').astype(str).apply(lambda x: ' '.join(x), axis=1)
    full_text = ' '.join(text_data)
    
    if full_text.strip():
        seg_list = jieba.cut(full_text)
        stopwords = set(['çš„', 'æ˜¯', 'åœ¨', 'æˆ‘', 'æœ‰', 'ä¹Ÿ', 'äº†', 'éƒ½', 'å€‹', 'å¾ˆ', 'å¯ä»¥', 'è€å¸«', 'è¬›å¸«',
                         ' ', 'ç„¡', 'æ²’æœ‰', 'å¸Œæœ›', 'è¦ºå¾—', 'èª²ç¨‹', 'éƒ¨åˆ†', 'ä»€éº¼', 'åœ°æ–¹', 'ä¸€äº›', 'é€™å€‹',
                         'the', 'to', 'and', 'a', 'test', 'ab', 'testing'])
        words = [word for word in seg_list if word not in stopwords and len(word) > 1]
        
        try:
            wordcloud = WordCloud(
                font_path='NotoSansTC-Regular.ttf', 
                width=800, height=400, background_color='white', collocations=False
            ).generate(" ".join(words))
            fig, ax = plt.subplots(figsize=(12, 6))
            ax.imshow(wordcloud, interpolation='bilinear')
            ax.axis('off')
            st.pyplot(fig)
        except Exception as e:
            st.error(f"ç”¢ç”Ÿè©žé›²æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    else:
        st.info("åœ¨ç›®å‰çš„ç¯©é¸æ¢ä»¶ä¸‹ï¼Œæ²’æœ‰è¶³å¤ çš„æ–‡å­—å›žé¥‹ä¾†ç”¢ç”Ÿè©žé›²ã€‚")

with tab3:
    st.header("å®Œæ•´å›žé¥‹ç•™è¨€")
    st.markdown("ä»¥ä¸‹æ˜¯ç¯©é¸å¾Œï¼Œæ¯ä»½å›žé¥‹çš„å®Œæ•´æ–‡å­—å…§å®¹ã€‚")

    # ä½¿ç”¨ reset_index() ä¾†ç”¢ç”Ÿä¸€å€‹åŒ¿åçš„åºè™Ÿ
    for index, row in filtered_df.reset_index(drop=True).iterrows():
        with st.expander(f"ðŸ’¬ å›žé¥‹ #{index + 1} ({row['role']})"):
            st.markdown(f"**ã€æœ€å¸å¼•æˆ‘çš„éƒ¨åˆ†ã€‘**\n> {row['attractive_part']}")
            st.markdown(f"**ã€æœŸå¾…èˆ‡å»ºè­°ã€‘**\n> {row['suggestions']}")
            st.markdown(f"**ã€çµ¦è¬›å¸«çš„å›žé¥‹ã€‘**\n> {row['feedback_to_lecturer']}")
            if pd.notna(row['additional_comments']) and row['additional_comments'].strip():
                st.markdown(f"**ã€è£œå……äº‹é …ã€‘**\n> {row['additional_comments']}")
