import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm # ã€æ ¸å¿ƒä¿®æ­£ã€‘å°Žå…¥å­—é«”ç®¡ç†å™¨
from wordcloud import WordCloud
import jieba
import os # å°Žå…¥ os æ¨¡çµ„ä¾†æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨

# --- é é¢è¨­å®š ---
st.set_page_config(
    page_title="DTDA ç¬¬8å ‚ç¤¾èª²å›žé¥‹å„€è¡¨æ¿",
    page_icon="ðŸ“Š",
    layout="wide"
)

# --- ã€æ ¸å¿ƒä¿®æ­£ã€‘æ‰‹å‹•è¨»å†Šä¸­æ–‡å­—é«” ---
# å­—é«”æª”æ¡ˆçš„è·¯å¾‘ (å› ç‚ºå­—é«”æª”è·Ÿ app.py åœ¨åŒä¸€å€‹ç›®éŒ„ï¼Œæ‰€ä»¥ç›´æŽ¥å¯«æª”åå³å¯)
FONT_PATH = 'NotoSansTC-Regular.ttf'

# æª¢æŸ¥å­—é«”æª”æ¡ˆæ˜¯å¦å­˜åœ¨
if os.path.exists(FONT_PATH):
    # å°‡å­—é«”è¨»å†Šåˆ° Matplotlib çš„å­—é«”ç®¡ç†å™¨
    fm.fontManager.addfont(FONT_PATH)
    
    # è¨­ç½® Matplotlib çš„é»˜èªå­—é«”
    # 'Noto Sans TC' æ˜¯é€™å€‹å­—é«”æª”æ¡ˆå…§éƒ¨å®šç¾©çš„åç¨±
    plt.rc('font', family='Noto Sans TC') 
    plt.rcParams['axes.unicode_minus'] = False # è§£æ±ºè² è™Ÿé¡¯ç¤ºå•é¡Œ
else:
    # å¦‚æžœåœ¨ Streamlit Cloud ä¸Šæ‰¾ä¸åˆ°å­—é«”æª”ï¼Œé¡¯ç¤ºéŒ¯èª¤è¨Šæ¯
    # é€™æœ‰åŠ©æ–¼éƒ¨ç½²æ™‚çš„åµéŒ¯
    st.error(f"å­—é«”æª”æ¡ˆæœªæ‰¾åˆ°: {FONT_PATH}ã€‚è«‹ç¢ºä¿ NotoSansTC-Regular.ttf å·²ç¶“ä¸Šå‚³åˆ° GitHub å„²å­˜åº«çš„æ ¹ç›®éŒ„ã€‚")


# --- è¼‰å…¥è³‡æ–™ (ä½¿ç”¨å¿«å–é¿å…é‡è¤‡è¼‰å…¥) ---
@st.cache_data
def load_data():
    df = pd.read_csv("feedback_data.csv")
    new_columns = [
        'role', 's_content', 's_lecturer', 's_structure', 's_practicality',
        's_knowledge', 's_interaction', 's_time', 's_overall', 'f_hypothesis',
        'f_p_value', 'f_error_type', 'f_ab_flow', 'f_ab_code', 'useful_content',
        'attractive_part', 'suggestions', 'feedback_to_lecturer', 'additional_comments'
    ]
    if len(df.columns) == len(new_columns):
        df.columns = new_columns
    else:
        raise ValueError(f"CSVæ¬„ä½æ•¸é‡({len(df.columns)})èˆ‡é æœŸ({len(new_columns)})ä¸ç¬¦ï¼")
    return df

df = load_data()

# --- å´é‚Šæ¬„ç¯©é¸å™¨ ---
st.sidebar.title("ç¯©é¸å™¨")
st.sidebar.markdown("---")
roles = df['role'].unique()
selected_roles = st.sidebar.multiselect(
    "é¸æ“‡èº«ä»½ï¼š",
    options=roles,
    default=roles
)

if selected_roles:
    filtered_df = df[df['role'].isin(selected_roles)]
else:
    filtered_df = df

# --- ä¸»ç•«é¢ ---
st.title("ðŸ“Š DTDA ä¸‹å­¸æœŸç¬¬8å ‚ç¤¾èª²å›žé¥‹å„€è¡¨æ¿")
st.markdown("æˆ‘å€‘æ•´ç†äº†A/B Testing ç¤¾èª²çš„ç¶œåˆå›žé¥‹ï¼Œå¯é€éŽå·¦å´ç¯©é¸å™¨æŸ¥çœ‹ä¸åŒèº«ä»½æˆå“¡çš„æ„è¦‹ã€‚")

# --- é—œéµæŒ‡æ¨™ (KPIs) ---
total_responses = len(filtered_df)
avg_satisfaction = filtered_df['s_overall'].mean()

col1, col2 = st.columns(2)
col1.metric("ç¸½å›žé¥‹æ•¸", f"{total_responses} ä»½")
col2.metric("å¹³å‡æ•´é«”æ»¿æ„åº¦", f"{avg_satisfaction:.2f} / 5.0")

st.markdown("---")

# --- å„€è¡¨æ¿å…§å®¹ (ä½¿ç”¨åˆ†é ) ---
tab1, tab2, tab3 = st.tabs(["ðŸ“ˆ æ»¿æ„åº¦èˆ‡ç†Ÿæ‚‰åº¦åˆ†æž", "â˜ï¸ æ–‡å­—å›žé¥‹èˆ‡è©žé›²", "ðŸ“„ å®Œæ•´å›žé¥‹ç•™è¨€"])

with tab1:
    st.header("å„é …æ»¿æ„åº¦èˆ‡ä¸»é¡Œç†Ÿæ‚‰åº¦åˆ†ä½ˆ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("èª²ç¨‹æ»¿æ„åº¦(1-5åˆ†)")
        satisfaction_cols_map = {
            's_content': 'èª²ç¨‹å…§å®¹', 's_lecturer': 'è¬›å¸«æŠ€å·§', 's_structure': 'èª²ç¨‹çµæ§‹',
            's_practicality': 'èª²ç¨‹å¯¦ç”¨æ€§', 's_knowledge': 'æ–°çŸ¥å­¸ç¿’', 's_interaction': 'äº’å‹•åƒèˆ‡',
            's_time': 'æ™‚é–“åˆç†æ€§', 's_overall': 'æ•´é«”æ»¿æ„åº¦'
        }
        satisfaction_data = filtered_df[satisfaction_cols_map.keys()].mean().rename(satisfaction_cols_map)
        
        fig, ax = plt.subplots(figsize=(10, 8))
        satisfaction_data.sort_values().plot(kind='barh', ax=ax, color='skyblue')
        ax.set_title('å„é …æ»¿æ„åº¦å¹³å‡åˆ†æ•¸')
        ax.set_xlabel('å¹³å‡åˆ†æ•¸')
        ax.set_xlim(0, 5.5)
        for index, value in enumerate(satisfaction_data.sort_values()):
            ax.text(value + 0.05, index, f'{value:.2f}')
        st.pyplot(fig)

    with col2:
        st.subheader("èª²å¾Œä¸»é¡Œç†Ÿæ‚‰åº¦(1-5åˆ†)")
        familiarity_cols_map = {
            'f_hypothesis': 'å‡è¨­æª¢å®š', 'f_p_value': 'På€¼æ¦‚å¿µ', 'f_error_type': 'åž‹ä¸€/äºŒéŒ¯èª¤',
            'f_ab_flow': 'A/B Testæµç¨‹', 'f_ab_code': 'A/B Testç¨‹å¼ç¢¼'
        }
        familiarity_data = filtered_df[familiarity_cols_map.keys()].mean().rename(familiarity_cols_map)

        fig, ax = plt.subplots(figsize=(10, 8))
        familiarity_data.sort_values().plot(kind='barh', ax=ax, color='lightgreen')
        ax.set_title('èª²å¾Œä¸»é¡Œç†Ÿæ‚‰åº¦å¹³å‡åˆ†æ•¸')
        ax.set_xlabel('å¹³å‡åˆ†æ•¸')
        ax.set_xlim(0, 5.5)
        for index, value in enumerate(familiarity_data.sort_values()):
            ax.text(value + 0.05, index, f'{value:.2f}')
        st.pyplot(fig)

with tab2:
    st.header("Word Cloud")
    
    text_cols = ['attractive_part', 'suggestions', 'feedback_to_lecturer', 'additional_comments']
    text_data = filtered_df[text_cols].fillna('').astype(str).apply(lambda x: ' '.join(x), axis=1)
    full_text = ' '.join(text_data)
    
    if full_text.strip():
        seg_list = jieba.cut(full_text)
        stopwords = set(['çš„', 'æ˜¯', 'åœ¨', 'æˆ‘', 'æœ‰', 'ä¹Ÿ', 'äº†', 'éƒ½', 'å€‹', 'å¾ˆ', 'å¯ä»¥', 'è€å¸«', 'è¬›å¸«',
                         ' ', 'ç„¡', 'æ²’æœ‰', 'å¸Œæœ›', 'è¦ºå¾—', 'èª²ç¨‹', 'éƒ¨åˆ†', 'ä»€éº¼', 'åœ°æ–¹', 'ä¸€äº›', 'é€™å€‹',
                         'the', 'to', 'and', 'a', 'test', 'ab', 'testing'])
        words = [word for word in seg_list if word not in stopwords and len(word) > 1]
        
        if words:
            try:
                wordcloud = WordCloud(
                    font_path=FONT_PATH, # ç›´æŽ¥ä½¿ç”¨æˆ‘å€‘å®šç¾©å¥½çš„å­—é«”è·¯å¾‘è®Šæ•¸
                    width=800, height=400, background_color='white', collocations=False
                ).generate(" ".join(words))
                fig, ax = plt.subplots(figsize=(12, 6))
                ax.imshow(wordcloud, interpolation='bilinear')
                ax.axis('off')
                st.pyplot(fig)
            except Exception as e:
                st.error(f"ç”¢ç”Ÿæ–‡å­—é›²æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        else:
            st.info("åœ¨ç›®å‰çš„ç¯©é¸æ¢ä»¶ä¸‹ï¼Œæ²’æœ‰è¶³å¤ çš„æ–‡å­—å›žé¥‹ä¾†ç”¢ç”Ÿæ–‡å­—é›²ã€‚")
    else:
        st.info("åœ¨ç›®å‰çš„ç¯©é¸æ¢ä»¶ä¸‹ï¼Œæ²’æœ‰è¶³å¤ çš„æ–‡å­—å›žé¥‹ä¾†ç”¢ç”Ÿæ–‡å­—é›²ã€‚")

with tab3:
    st.header("å®Œæ•´å›žé¥‹ç•™è¨€")
    st.markdown("ä»¥ä¸‹æ˜¯ç¯©é¸å¾Œï¼Œæ¯ä»½å›žé¥‹çš„å®Œæ•´æ–‡å­—å…§å®¹ã€‚")

    for index, row in filtered_df.reset_index(drop=True).iterrows():
        with st.expander(f"ðŸ’¬ å›žé¥‹ #{index + 1} ({row['role']})"):
            st.markdown(f"**ã€æœ€å¸å¼•æˆ‘çš„éƒ¨åˆ†ã€‘**\n> {row['attractive_part']}")
            st.markdown(f"**ã€æœŸå¾…èˆ‡å»ºè­°ã€‘**\n> {row['suggestions']}")
            st.markdown(f"**ã€çµ¦è¬›å¸«çš„å›žé¥‹ã€‘**\n> {row['feedback_to_lecturer']}")
            if pd.notna(row['additional_comments']) and row['additional_comments'].strip():
                st.markdown(f"**ã€è£œå……äº‹é …ã€‘**\n> {row['additional_comments']}")
